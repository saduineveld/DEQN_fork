constants:
  constants:
    alpha: 0.36
    beta: 0.985
    delta: 0.025
    nu: 2
    eta: 4
    rho_z: 0.95
    sigma_z: 0.01
    chi: 1
    zss: 1
    lK0: 2.9
    lZ0: 0
net:
  layers:
  - hidden:
      units: 50
      type: dense
      activation: relu
      init_scale: 1.0
  - hidden:
      units: 50
      type: dense
      activation: relu
      init_scale: 1.0
  - output:
      type: dense
      activation: sigmoid
      init_scale: 0.1
optimizer:
  optimizer: Adam
  learning_rate: 0.0001
  clipvalue: 1.0
run:
  N_sim_batch: 64
  N_episode_length: 1
  N_epochs_per_episode: 1
  N_minibatch_size: 64
  N_episodes: 2001
  keras_precision: float32
variables:
  states:
  - name: lKt
    init:
      distribution: truncated_normal
      kwargs:
        mean: 2.9
        stddev: 0.0
  - name: lZt
    init:
      distribution: truncated_normal
      kwargs:
        mean: 0.0
        stddev: 0.0
  policies:
  - name: lCt
  definitions:
  - name: get_lKn
  - name: get_RHSt
  - name: get_Kt
  - name: get_Zt
  - name: get_Ct
  - name: get_marg_ut
  - name: get_Ht
  - name: get_Yt
  - name: get_Rt
seed: 42
STARTING_POINT: LATEST
CHECKPOINT_INTERVAL: 2
MAX_TO_KEEP_NUMBER: 10
MODEL_NAME: RBC
initialize_each_episode: true
error_filename: error_file.txt
enable_check_numerics: false
